{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\ralvarez\\Anaconda\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "%config IPCompleter.greedy=True\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "\n",
    "import pandas as pd\n",
    "import nltk.data\n",
    "import re, string, unicodedata\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Data/Flujo1.csv\", sep=\";\")\n",
    "df['Respuesta'] = df['Respuesta'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load('../modelWord2vec.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_vectors(array_text):\n",
    "    array_vectors = []\n",
    "    for word in array_text:\n",
    "        array_vectors.append(model.wv['word'])\n",
    "    return np.array(array_vectors)\n",
    "data = pd.DataFrame()\n",
    "data['_vectors'] = df[\"Respuesta\"].apply(text_to_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_vector(vectors):\n",
    "    return np.mean(vectors, axis=0)\n",
    "data['_vectors'] = data[\"_vectors\"].apply(get_mean_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dimensions = df.Dimension.unique().tolist()\n",
    "def enumerate_dimensions(dimension):\n",
    "    return list_dimensions.index(dimension)\n",
    "data['_dimension'] = df.Dimension.apply(enumerate_dimensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba con Keras Preprocessing .... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_phrases(tokens):\n",
    "    string = \"\"\n",
    "    for token in tokens:\n",
    "        string = string + token + \" \"\n",
    "    return string\n",
    "# make_phrases(df.Respuesta[0])\n",
    "df.Respuesta = df.Respuesta.apply(make_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dimensions = df.Dimension.unique().tolist()\n",
    "def enumerate_dimensions(dimension):\n",
    "    return list_dimensions.index(dimension)\n",
    "df.Dimension = df.Dimension.apply(enumerate_dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df.Respuesta.values)\n",
    "sequences = tokenizer.texts_to_sequences(df.Respuesta.values)\n",
    "vocab = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pad_sequences(sequences, maxlen=10, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.Dimension.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0923 01:12:31.093281 16288 deprecation.py:506] From C:\\Users\\ralvarez\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0923 01:12:31.132297 16288 deprecation.py:506] From C:\\Users\\ralvarez\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0923 01:12:31.190546 16288 deprecation.py:323] From C:\\Users\\ralvarez\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, Flatten\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab, output_dim=10, input_length=10))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early = EarlyStopping(monitor='val_loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 119956 samples, validate on 39986 samples\n",
      "119956/119956 [==============================] - 4s 30us/sample - loss: -440.6986 - acc: 0.0681 - val_loss: -1329.6993 - val_acc: 0.0664\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=128, validation_data=(X_test, y_test), callbacks=[early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 10, 10)            308780    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 308,881\n",
      "Trainable params: 308,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [-440.6985732008185],\n",
       " 'acc': [0.06809163],\n",
       " 'val_loss': [-1329.6993021532146],\n",
       " 'val_acc': [0.06637323]}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model=model, texto='realmente tiene muchos problemas, como gobierno y temas de finanzas'):\n",
    "    x = np.array([texto])\n",
    "    seq = tokenizer.texts_to_sequences(x)\n",
    "    padded = pad_sequences(seq, maxlen=10, padding='post')\n",
    "    pred = model.predict_classes(padded)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 119956 samples, validate on 39986 samples\n",
      "Epoch 1/10\n",
      "119956/119956 [==============================] - 9s 77us/sample - loss: -3598195514.1325 - acc: 0.0679 - val_loss: -71793612390.3590 - val_acc: 0.0672\n",
      "Epoch 2/10\n",
      "119956/119956 [==============================] - 6s 53us/sample - loss: -623379425110738.7500 - acc: 0.0679 - val_loss: -5547264579771106.0000 - val_acc: 0.0672\n",
      "Epoch 3/10\n",
      "119956/119956 [==============================] - 8s 65us/sample - loss: -521552944368277248.0000 - acc: 0.0679 - val_loss: -2886669301739348480.0000 - val_acc: 0.0672\n",
      "Epoch 4/10\n",
      "119956/119956 [==============================] - 7s 57us/sample - loss: -47296521307760549888.0000 - acc: 0.0679 - val_loss: -186500390657319600128.0000 - val_acc: 0.0672\n",
      "Epoch 5/10\n",
      "119956/119956 [==============================] - 9s 79us/sample - loss: nan - acc: 0.0353 - val_loss: nan - val_acc: 0.0127\n",
      "Epoch 6/10\n",
      "119956/119956 [==============================] - 7s 60us/sample - loss: nan - acc: 0.0135 - val_loss: nan - val_acc: 0.0127\n",
      "Epoch 7/10\n",
      "119956/119956 [==============================] - 8s 68us/sample - loss: nan - acc: 0.0135 - val_loss: nan - val_acc: 0.0127\n",
      "Epoch 8/10\n",
      "119956/119956 [==============================] - 7s 59us/sample - loss: nan - acc: 0.0135 - val_loss: nan - val_acc: 0.0127\n",
      "Epoch 9/10\n",
      "119956/119956 [==============================] - 9s 73us/sample - loss: nan - acc: 0.0135 - val_loss: nan - val_acc: 0.0127\n",
      "Epoch 10/10\n",
      "119956/119956 [==============================] - 7s 61us/sample - loss: nan - acc: 0.0135 - val_loss: nan - val_acc: 0.0127\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import LSTM, Dropout\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab, output_dim=10, input_length=10))\n",
    "model.add(LSTM(10, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=512, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x16906f14940>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
