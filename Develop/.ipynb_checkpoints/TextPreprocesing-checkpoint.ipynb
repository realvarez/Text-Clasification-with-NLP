{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "import pandas as pd\n",
    "import re,nltk, string, unicodedata\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.options.display.max_rows = 500\n",
    "df = pd.read_csv(\"Data/formattedData.csv\", sep=\";\").dropna()\n",
    "df = df[df['Area']!= 'Confianza General']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSntTok = df\n",
    "dfSntTok[\"Respuesta\"] = dfSntTok[\"Respuesta\"].apply(nltk.sent_tokenize)\n",
    "dfSntTok = dfSntTok[dfSntTok['Respuesta'].apply(len) >= 1].dropna()\n",
    "arrayExterno = []\n",
    "def separeSentences(row):\n",
    "    if type(row['Respuesta']) != str:\n",
    "        if len(row['Respuesta']) == 1:\n",
    "            row['Respuesta'] = row['Respuesta'][0]\n",
    "            return row\n",
    "        else:\n",
    "            area = row['Area']\n",
    "            dimension = row['Dimension']\n",
    "            for sent in row['Respuesta']:\n",
    "                tempArray = []\n",
    "                tempArray.append(area)    \n",
    "                tempArray.append(dimension)\n",
    "                tempArray.append(sent)\n",
    "                arrayExterno.append(tempArray)\n",
    "            row['Respuesta'] = \"\"\n",
    "            return row\n",
    "    else:\n",
    "        return row\n",
    "\n",
    "dfSntTok = dfSntTok.apply(separeSentences, axis = 1).copy()\n",
    "dfSntTok = pd.concat([dfSntTok,\n",
    "                      pd.DataFrame(arrayExterno, columns=[\"Area\", \"Dimension\", \"Respuesta\"])],ignore_index=True).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeText(tokens):\n",
    "    tokens = tokens.replace(r'_', r'').replace(r'¨¢', r'a').replace(r'¨¦',r'e').replace(r'¨ª', r'i')\\\n",
    "        .replace(r'¨²', r'u').replace(r'¨®', r'o').replace(r'?', r'n').replace(r'á', r'a')\\\n",
    "        .replace(r'é',r'e').replace(r'í', r'i').replace(r'ó', r'o').replace(r'ú', r'u').replace(r'ñ', r'n')\\\n",
    "        .replace('Á', r'A').replace(r'É',r'E').replace(r'Í', r'I').replace(r'Ó', r'O').replace(r'Ú', r'U')\\\n",
    "        .replace(r'Ñ', r'N')\n",
    "    tokens = re.sub(r'[^\\w\\s ÑñáéíóúÁÉÍÓÚ]', '', tokens)\n",
    "    tokens = re.sub('\\d','',tokens)\n",
    "    return tokens.lower()\n",
    "\n",
    "stop = stopwords.words('spanish')\n",
    "def removeStopWords(tokens, stopword):\n",
    "    new_ = []\n",
    "    for token in tokens:\n",
    "        if token not in stopword and token not in ['etc']:\n",
    "            new_.append(token)\n",
    "    return new_\n",
    "\n",
    "dfNorm = dfSntTok.copy()\n",
    "dfNorm[\"Respuesta\"] = dfNorm[\"Respuesta\"].apply(normalizeText)\\\n",
    "                                         .apply(nltk.word_tokenize)\\\n",
    "                                         .apply(removeStopWords, stopword = stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    152003.00000\n",
       "mean          6.52418\n",
       "std           2.19957\n",
       "min           4.00000\n",
       "25%           5.00000\n",
       "50%           6.00000\n",
       "75%           8.00000\n",
       "max          10.00000\n",
       "Name: Respuesta, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfNorm = dfNorm[dfNorm['Respuesta'].map(len) > 3]\n",
    "dfNorm[\"Respuesta\"] = dfNorm[\"Respuesta\"].apply(lambda x: x if len(x) < 10 else x[:10])\n",
    "dfNorm[\"Respuesta\"].apply(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'whiskers': [<matplotlib.lines.Line2D at 0x7f1ae0835a00>,\n",
       "  <matplotlib.lines.Line2D at 0x7f1ae0835880>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x7f1ae9065f70>,\n",
       "  <matplotlib.lines.Line2D at 0x7f1ae4ddb880>],\n",
       " 'boxes': [<matplotlib.lines.Line2D at 0x7f1aeb50ab50>],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x7f1ae1601e80>],\n",
       " 'fliers': [<matplotlib.lines.Line2D at 0x7f1ae1601940>],\n",
       " 'means': []}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplots()\n",
    "dataToPlot = [dfNorm[\"Respuesta\"].apply(len)]\n",
    "plt.boxplot(dataToPlot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    148618.000000\n",
       "mean          6.521014\n",
       "std           2.199150\n",
       "min           4.000000\n",
       "25%           5.000000\n",
       "50%           6.000000\n",
       "75%           8.000000\n",
       "max          10.000000\n",
       "Name: Respuesta, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfNorm.groupby(['Area','Dimension']).count().Respuesta\n",
    "dfNorm[\"Respuesta\"].apply(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_quantity = max(dfNorm.groupby(['Area','Dimension']).count().Respuesta)\n",
    "array_groups_to_remove = []\n",
    "for name, group in dfNorm.groupby(['Area','Dimension']):\n",
    "    if len(group) <= max_quantity/10:\n",
    "        array_groups_to_remove.append(name)\n",
    "\n",
    "dfNorm = dfNorm.apply(lambda x, arr_rem: None if (x['Area'],x['Dimension']) in arr_rem else x, axis = 1\\\n",
    "                      , arr_rem = array_groups_to_remove).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Area                  Dimension                   \n",
       "Gobierno Corporativo  Anti-corrupción                  7004\n",
       "                      Integridad                       7186\n",
       "Medio Ambiente        Ambiental                        2137\n",
       "                      Cultura Ambiental               10875\n",
       "Social Externo        Calidad                          6744\n",
       "                      Cliente                          5811\n",
       "                      Comunicación                     3195\n",
       "                      Comunidad                        4939\n",
       "                      Educación                        1928\n",
       "                      Imagen                           6414\n",
       "                      Infraestructura                  2055\n",
       "                      Operación                        2079\n",
       "                      Proveedores                      2078\n",
       "                      Reclamos                         5865\n",
       "                      Recompra                        16273\n",
       "                      Salud & Seguridad                4497\n",
       "                      Trabajo                          1985\n",
       "                      Valor                            6175\n",
       "Social Interno        Compromiso                       5571\n",
       "                      Comunicación                     5676\n",
       "                      Diversidad e Inclusión           2580\n",
       "                      Empleados                       10057\n",
       "                      Entrenamiento y Desarrollo       6084\n",
       "                      Equilibrio Vida-Trabajo          5766\n",
       "                      Estructura de Compensaciones     6735\n",
       "                      Identidad Cultural               2579\n",
       "                      Salud & Seguridad                6330\n",
       "Name: Respuesta, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfNorm.groupby(['Area','Dimension']).count().Respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    165450.000000\n",
       "mean     6.573460     \n",
       "std      2.213859     \n",
       "min      4.000000     \n",
       "25%      5.000000     \n",
       "50%      6.000000     \n",
       "75%      9.000000     \n",
       "max      10.000000    \n",
       "Name: Respuesta, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmaDiccionario = {}\n",
    "with open('Herramientas/lemma.txt', 'rb') as fichero:\n",
    "    datos = (fichero.read().decode('utf8').replace(u'\\r', u'').split(u'\\n'))\n",
    "    datos = ([avance.split(u'\\t') for avance in datos])\n",
    "for avance in datos:\n",
    "   if len(avance) >1:\n",
    "      lemmaDiccionario[avance[1]] = avance[0]\n",
    "        \n",
    "def lemmatize(word):\n",
    "   return lemmaDiccionario.get(word, word + u'')\n",
    "   \n",
    "def lemmatize_words(words):\n",
    "    new_words = []\n",
    "    for palabra in words:\n",
    "        new_word = lemmatize(palabra)\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "dfNorm[\"Respuesta\"] = dfNorm[\"Respuesta\"].apply(lemmatize_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNorm.to_csv(\"Data/Flujo1.csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stemmer_spanish = SnowballStemmer('spanish')\n",
    "def stemWordsArray(tokens, stemmer):\n",
    "    new_ = []\n",
    "    for token in tokens:\n",
    "        new_.append(stemmer.stem(token))\n",
    "    return new_\n",
    "\n",
    "dfStemmer = dfNorm.copy()\n",
    "dfStemmer['Respuesta'] = dfStemmer['Respuesta'].apply(stemWordsArray, stemmer = Stemmer_spanish)\n",
    "dfStemmer.to_csv(\"Data/Flujo2.csv\", sep=\";\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
